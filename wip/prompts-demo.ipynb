{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44f9bf75-cf85-4c50-af10-00bc6e45971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "from langchain_community.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea83067c-40b9-45d3-9e6f-d7b49cad722d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4dae365-2044-42dc-8f9a-5afd32121779",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0.5)\n",
    "#to determine whether value coming out is more creative or more detreministic temperature varies from 0 to 2,\n",
    "#value closer to zero means it is more deterministic more fact based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91d413a7-d8ad-4d62-a501-1de2087accb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Why did the British weather feel so depressed?\n",
      "\n",
      "Because it was always raining on its parade.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "prompt = prompt_template.format(adjective=\"sad\", content=\"British Weather\")\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "print(response)\n",
    "#ZERO SHOT PROMPT TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8ed57bf-efa7-4c29-8085-10ff6df8b237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef5856e2-bb20-4efe-b26d-176183daba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e51a6a6b-b9f6-4503-8ca3-a9924d3adbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI: My name is Bob and I am good at providing helpful responses and assisting with tasks. Is there something specific you need help with?\n"
     ]
    }
   ],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\", \"Hello how are you doing?\"),\n",
    "        (\"ai\", \"I am doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "prompt = chat_template.format_messages(name=\"Bob\", user_input=\"What is your name and what are you good at?\")\n",
    "response = model.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab63cf00-2831-439c-ab9d-8a3c87332eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Various ways of formatting System/Human/AI prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55d9e1c3-71aa-4eff-a132-70f4f3fbffe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "System: I prefer to indulge in nourishing treats.\n"
     ]
    }
   ],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"You are a helpful assistant that re-writes the user's text to \"\n",
    "                \"sound more upbeat.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "prompt = chat_template.format_messages(text=\"I don't like eating tasty things\")\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79b4a43c-b084-498e-b63e-c2eb042d691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Providing a Context along with the Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cc7ce47-2702-4e9d-8be1-18bc9b47cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer \n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language Models (LLMs) are the largest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled appplications. These models \n",
    "can be accesssed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\n",
    "Question: Which libraries and model offer LLMs?\n",
    "Answer: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6a46c92-e70e-4410-bb53-06c627a8a82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The libraries that offer LLMs are Hugging Face's `transformers` library, OpenAI's `openai` library, and Cohere's `cohere` library. \n"
     ]
    }
   ],
   "source": [
    "print(model.invoke(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4591a763-cf17-4b47-9588-7502c62286da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LANGCHAIN FEW SHOT PROMPT TEMPLATE\n",
    "\n",
    "# IT SELECTS EXAMPLES BASED ON INPUT\n",
    "\n",
    "###HERE ARE EXAMPLES AND THE OUTCOME SHOULD BE INLINE WITH THE WAY OF THE EXAMPLES###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ea4ed65-eb77-4e96-b11f-8cfca9c70b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate\n",
    "\n",
    "#CREATE OUR EXAMPLES\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"How are you?\",\n",
    "        \"answer\":\"I can't complain but sometimes I still do.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\":\"What time is it?\",\n",
    "        \"answer\":\"It's time to get a watch.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "#CREATE A EXAMPLE TEMPLATE\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI:{answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38146256-d11c-4728-ab89-77bfa76092db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING A PROMPT FROM THE TEMPLATE\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "#NOW BREAK OUR PREVIOUS PROMPT INTO A PREFIX AND SUFFIX\n",
    "#THE PREFIX IS OUR INSTRUCTIONS\n",
    "\n",
    "prefix= \"\"\"The following are exerpts from conservations with an AI\n",
    "assistant. The assistant is typically sarcastic and witty, producing \n",
    "creative and funny responses to the user questions. Here are some \n",
    "examples:\n",
    "\"\"\"\n",
    "\n",
    "#AND THE SUFFIX OUR USER INPUT AND OUTPUT INDICATOR\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "204f0937-a907-43d9-bbed-da94f8fd566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOW CREATE THE FEW SHOT PROMPT TEMPLATE\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6b22632-3d47-4839-9453-30b67be9f530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are exerpts from conservations with an AI\n",
      "assistant. The assistant is typically sarcastic and witty, producing \n",
      "creative and funny responses to the user questions. Here are some \n",
      "examples:\n",
      "\n",
      "\n",
      "\n",
      "User: How are you?\n",
      "AI:I can't complain but sometimes I still do.\n",
      "\n",
      "\n",
      "\n",
      "User: What time is it?\n",
      "AI:It's time to get a watch.\n",
      "\n",
      "\n",
      "\n",
      "User: What movie should I watch this evening?\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "query = \"What movie should I watch this evening?\"\n",
    "\n",
    "print(few_shot_prompt_template.format(query=query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc1d1b79-bcd1-4121-8f4b-232902c49fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well, I don\\'t know your taste in movies, but I heard \"The Room\" is a cinematic masterpiece. Just kidding, please don\\'t watch that. Maybe go for something more mainstream like \"The Shawshank Redemption.\" Can\\'t go wrong with that one.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = few_shot_prompt_template | model\n",
    "\n",
    "chain.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff2ac9-439c-42c9-91ec-e7123f729084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
